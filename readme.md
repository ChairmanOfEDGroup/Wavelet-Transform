课题想法 1：量化压缩率与模型性能的“甜点区” (The Sweet Spot)
课题名称： 小波变换压缩率对深度学习模型分类性能的量化影响研究

研究背景与动机：
数据存储和传输是有成本的。在许多场景下，我们需要在不显著牺牲模型精度的前提下，尽可能地压缩图像数据。那么，这个“显著牺牲”的临界点在哪里？是否存在一个“甜点区”，既能获得可观的压缩比，又能将模型性能的损失降到最低？

核心研究问题：

随着小波压缩率（保留的系数百分比）的提高，模型ResNet的准确率是如何变化的？这个关系是线性的还是非线性的？

研究方法：

数据集准备： 选择乳腺癌据集。使用 PyWavelets 库，生成多个版本的训练集和测试集。

模型训练： 选择ResNet-50。在每个压缩版本的数据集上，进行迁移学习。

性能评估： 记录每个模型在对应压缩版本的验证集上的准确率。绘制“压缩率 vs. 准确率”曲线。

分析： 对比不同模型和数据集下的曲线，找出性能急剧下降的拐点，并分析其原因。

预期成果与意义：

为特定任务提供数据压缩的实践指导，帮助工程师在存储成本和模型性能之间做出明智决策。

揭示不同深度学习模型对信息冗余和压缩伪影的鲁棒性差异。

课题想法 2：小波压缩作为一种新型数据增强手段
课题名称： 基于小波压缩的数据增强对模型鲁棒性与泛化能力的影响研究

研究背景与动机：
小数据增强（如旋转、裁剪、色彩抖动）是防止模型过拟合、提升其泛化能力的关键技术。小波压缩会引入独特的伪影，这可以被看作是一种特殊的“噪声”。让模型在训练中“见识”过这种噪声，是否能让它变得更强大，对未知的干扰更具抵抗力？

核心研究问题：

将小波压缩图像（以不同压缩率）混入原始训练集，是否能提升模型在标准测试集上的性能？

研究方法：

数据集构建： 在原始训练数据的基础上，动态（on-the-fly）或离线地生成小波压缩的副本，与原始图像混合，组成新的增强训练集。

对比实验：

基线模型 (Baseline): 只使用标准数据增强（旋转、翻转等）进行训练。

实验模型 (Experimental): 在基线增强的基础上，额外加入小波压缩增强。

预期成果与意义：

提出一种可能有效的新型数据增强技术。

即模型通过学习“压缩伪影”的模式，可能学到了更本质、更抗干扰的特征。